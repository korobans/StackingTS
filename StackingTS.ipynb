{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "91c0e0e7-366c-4861-ada3-a18b1375182a",
   "metadata": {},
   "source": [
    "## Выбросы"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6925cfa-7bf8-43e8-a759-154ae82971c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def outliers(jeans):\n",
    "    season_data = pd.DataFrame({'ds': jeans.index, 'y': jeans.values})\n",
    "    \n",
    "    # Создание модели Prophet с уменьшенной чувствительностью к выбросам\n",
    "    model = Prophet(yearly_seasonality=True)\n",
    "    \n",
    "    model.fit(season_data)\n",
    "    \n",
    "    # Прогнозирование на тех же временных точках (исторический прогноз)\n",
    "    forecast = model.predict(season_data)\n",
    "    \n",
    "    # Вычисление остатков\n",
    "    residuals = season_data['y'] - forecast['yhat']\n",
    "    \n",
    "    # Расчёт стандартного отклонения остатков\n",
    "    std_res = residuals.std()\n",
    "    \n",
    "    # Определение порога для выбросов: 2.48 * стандартное отклонение\n",
    "    threshold = 5 * std_res\n",
    "    \n",
    "    # Нахождение индексов точек, где абсолютное значение остатка больше порога\n",
    "    outlier_mask = np.abs(residuals) > threshold\n",
    "    outlier_indices = residuals.index[outlier_mask]\n",
    "        \n",
    "    # Коррекция выбросов: для каждой точки, где наблюдается выброс,\n",
    "    # вычитаем остаток из исходного значения (результат становится равен предсказанному значению)\n",
    "    season_data_corrected = season_data.copy()\n",
    "    season_data_corrected.loc[outlier_indices, 'y'] = season_data_corrected.loc[outlier_indices, 'y'] - residuals.loc[outlier_indices]\n",
    "    \n",
    "    jeans = season_data_corrected\n",
    "    jeans = jeans.set_index('ds')['y']\n",
    "    return jeans"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3ed81c2-3637-4262-aa7c-27e20c3ff9fd",
   "metadata": {},
   "source": [
    "## Структурные сдвиги"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5045a6fe-c48b-4f4d-9bc4-ae98332ea5f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def deviation_generating(jeans, seasonality, adv_actual, cost_actual, leftovers):\n",
    "    common_index = jeans.index.intersection(seasonality.index).intersection(adv_actual.index).intersection(cost_actual.index)\n",
    "    \n",
    "    # Обрезаем все временные ряды по общему индексу\n",
    "    deviation_jeans = jeans.loc[common_index]\n",
    "    deviation_seasonality = seasonality.loc[common_index]\n",
    "    deviation_advertising = adv_actual.loc[common_index]\n",
    "    deviation_leftovers = leftovers.loc[common_index]\n",
    "    deviation_cost = cost_actual.loc[common_index]\n",
    "    \n",
    "    # Основной временной ряд (например, заказы)\n",
    "    signal = deviation_jeans.values\n",
    "    \n",
    "    # Преобразуем регрессоры в нужный формат\n",
    "    X_seasonality = deviation_seasonality.values.reshape(-1, 1)\n",
    "    X_advertising = deviation_advertising.values.reshape(-1, 1)\n",
    "    X_leftovers = deviation_leftovers.values.reshape(-1, 1)\n",
    "    X_cost = deviation_cost.values.reshape(-1, 1)\n",
    "    \n",
    "    # Объединяем все регрессоры в одну матрицу признаков\n",
    "    X = np.hstack([X_seasonality, X_advertising, X_leftovers, X_cost])\n",
    "    \n",
    "    # Обучаем линейную регрессию с ограничением на положительные коэффициенты\n",
    "    model = LinearRegression(positive=True)\n",
    "    model.fit(X, signal)\n",
    "    trend = model.predict(X)\n",
    "    \n",
    "    residuals = signal - trend\n",
    "    \n",
    "    # Поиск структурных сдвигов в остатках\n",
    "    algo = rpt.Binseg(model=\"l2\").fit(residuals)\n",
    "    breakpoints = algo.predict(pen=7000)  # Параметр pen можно корректировать для точности\n",
    "    \n",
    "    def generate_regressor_series(data, breakpoints):\n",
    "        \"\"\"\n",
    "        Генерирует булевый регрессорский ряд на основе списка точек разбиения.\n",
    "        \n",
    "        :param data: Pandas Series, исходный временной ряд\n",
    "        :param breakpoints: List[int], список индексов разбиения\n",
    "        :return: Pandas Series, расширенный ряд булевых значений\n",
    "        \"\"\"\n",
    "        L = len(data)\n",
    "        extended_length = L + 31  # Расширяем на 31 точку\n",
    "        regressor = np.zeros(extended_length, dtype=bool)\n",
    "        \n",
    "        # Заполняем булевый массив по сегментам\n",
    "        segments = [0] + breakpoints + [extended_length]\n",
    "        for i in range(0, len(segments) - 1, 2):\n",
    "            regressor[segments[i]:segments[i+1]] = True\n",
    "        \n",
    "        # Определяем частоту временного ряда\n",
    "        freq = pd.infer_freq(data.index)\n",
    "        if freq is None:\n",
    "            freq = 'D'\n",
    "        \n",
    "        # Генерируем расширенный индекс\n",
    "        extended_index = pd.date_range(start=data.index[0], periods=extended_length, freq=freq)\n",
    "        \n",
    "        return pd.Series(regressor, index=extended_index)\n",
    "    \n",
    "    # Пример использования:\n",
    "    breakpoints_sep = breakpoints[:-1] # [203, 351]\n",
    "    regressor_series = generate_regressor_series(jeans, breakpoints_sep)\n",
    "    deviation_regressor = regressor_series\n",
    "    \n",
    "    deviation_regressor = ~deviation_regressor\n",
    "    return deviation_regressor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5146fc1-e0d6-4268-b9f0-dae386ad64c6",
   "metadata": {},
   "source": [
    "## Prophet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9ddfba8-0b5c-4f45-84b5-1ce47a64d43f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from prophet import Prophet\n",
    "\n",
    "def prophet_fn(\n",
    "    jeans: pd.Series,\n",
    "    advertising: pd.Series,\n",
    "    seasonality: pd.Series,\n",
    "    deviation_regressor: pd.Series,\n",
    "    leftovers: pd.Series,\n",
    "    cost: pd.Series,\n",
    "    n_future: int\n",
    ") -> pd.Series:\n",
    "\n",
    "    series_list = [jeans, advertising, seasonality, deviation_regressor, leftovers, cost]\n",
    "    # начальные даты (учитываем только непустые значения)\n",
    "    start_dates = [s.dropna().index.min() for s in series_list]\n",
    "    # последние доступные даты\n",
    "    end_dates   = [s.index.max() for s in series_list]\n",
    "    common_start = max(start_dates)\n",
    "    common_end   = min(end_dates)\n",
    "\n",
    "    # 2) Создаём равномерный индекс по дням для исторического периода\n",
    "    hist_idx = pd.date_range(start=common_start, end=common_end, freq='D')\n",
    "\n",
    "    # 3) Рейнжируем и заполняем пропуски (регрессоры — заполнением вперед, потом нулями)\n",
    "    jeans_hist       = jeans.reindex(hist_idx)\n",
    "    advertising_hist = advertising.reindex(hist_idx).fillna(method='ffill').fillna(0)\n",
    "    seasonality_hist = seasonality.reindex(hist_idx).fillna(method='ffill').fillna(0)\n",
    "    deviation_hist   = deviation_regressor.reindex(hist_idx).fillna(method='ffill').fillna(0)\n",
    "    leftovers_hist   = leftovers.reindex(hist_idx).fillna(method='ffill').fillna(0)\n",
    "    cost_hist        = cost.reindex(hist_idx).fillna(method='ffill').fillna(0)\n",
    "\n",
    "    # 4) Формируем DataFrame для обучения и удаляем строки с NaN в y\n",
    "    prophet_df = pd.DataFrame({\n",
    "        'ds': hist_idx,\n",
    "        'y': jeans_hist.values,\n",
    "        'regressor': advertising_hist.values,\n",
    "        'seasonality': seasonality_hist.values,\n",
    "        'deviation': deviation_hist.values,\n",
    "        'leftovers': leftovers_hist.values,\n",
    "        'cost': cost_hist.values\n",
    "    }).dropna(subset=['y'])\n",
    "\n",
    "    # 5) Инициализация и обучение модели\n",
    "    model = Prophet(weekly_seasonality=True, mcmc_samples=800)\n",
    "    for reg in ['regressor', 'seasonality', 'deviation', 'leftovers', 'cost']:\n",
    "        model.add_regressor(reg)\n",
    "    model.fit(prophet_df)\n",
    "\n",
    "    # 6) Построение будущего датафрейма\n",
    "    future = model.make_future_dataframe(periods=n_future, freq='D')\n",
    "    future_idx = future['ds']\n",
    "\n",
    "    # 7) Подготавливаем регрессоры для будущего (заполнение аналогично историческому)\n",
    "    future['regressor']  = advertising.reindex(future_idx).fillna(method='ffill').fillna(0).values\n",
    "    future['seasonality'] = seasonality.reindex(future_idx).fillna(method='ffill').fillna(0).values\n",
    "    future['deviation']   = deviation_regressor.reindex(future_idx).fillna(method='ffill').fillna(0).values\n",
    "    future['leftovers']   = leftovers.reindex(future_idx).fillna(method='ffill').fillna(0).values\n",
    "    future['cost']        = cost.reindex(future_idx).fillna(method='ffill').fillna(0).values\n",
    "\n",
    "\n",
    "    # 8) Прогноз\n",
    "    forecast = model.predict(future)\n",
    "\n",
    "    # Возвращаем только новые даты после исторического конца\n",
    "    result = forecast.set_index('ds')['yhat']\n",
    "    return result[result.index > common_end]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31cd1b5c-c9f0-44e2-bdda-c6c7f80a32cb",
   "metadata": {},
   "source": [
    "## SARIMA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "540446cc-a5df-49f7-b36d-254768783d5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "\n",
    "def sarima_fn(\n",
    "    advertising: pd.Series,\n",
    "    seasonality: pd.Series,\n",
    "    jeans: pd.Series,\n",
    "    deviation_regressor: pd.Series,\n",
    "    leftovers: pd.Series,\n",
    "    cost: pd.Series,\n",
    "    p: int,\n",
    "    d: int,\n",
    "    q: int,\n",
    "    P: int,\n",
    "    D: int,\n",
    "    Q: int,\n",
    "    m: int,\n",
    "    n_future: int,\n",
    "    need_summary: bool\n",
    ") -> pd.Series:\n",
    "\n",
    "    deviation_regressor = deviation_regressor.astype(int)\n",
    "    leftovers = leftovers.astype(int)\n",
    "    \n",
    "    # 1) Определяем общий период, где есть данные во всех сериях\n",
    "    series_list = [jeans, advertising, seasonality, deviation_regressor, leftovers, cost]\n",
    "    start_dates = [s.dropna().index.min() for s in series_list]\n",
    "    end_dates = [s.index.max() for s in series_list]\n",
    "    common_start = max(start_dates)\n",
    "    common_end = min(end_dates)\n",
    "\n",
    "    # 2) Создаем единый дневной индекс\n",
    "    hist_idx = pd.date_range(start=common_start, end=common_end, freq='D')\n",
    "\n",
    "    # 3) Реиндексация и заполнение\n",
    "    jeans_hist = jeans.reindex(hist_idx)\n",
    "    ad_hist = advertising.reindex(hist_idx).fillna(method='ffill').fillna(0)\n",
    "    seas_hist = seasonality.reindex(hist_idx).fillna(method='ffill').fillna(0)\n",
    "    dev_hist = deviation_regressor.reindex(hist_idx).fillna(method='ffill').fillna(0)\n",
    "    left_hist = leftovers.reindex(hist_idx).fillna(method='ffill').fillna(0)\n",
    "    cost_hist = cost.reindex(hist_idx).fillna(method='ffill').fillna(0)\n",
    "\n",
    "    # 4) Формируем DataFrame и убираем даты без y\n",
    "    df_train = pd.DataFrame({\n",
    "        'jeans': jeans_hist.values,\n",
    "        'advertising': ad_hist.values,\n",
    "        'seasonality': seas_hist.values,\n",
    "        'deviation': dev_hist.values,\n",
    "        'leftovers': left_hist.values,\n",
    "        'cost': cost_hist.values\n",
    "    }, index=hist_idx).dropna(subset=['jeans'])\n",
    "\n",
    "    end_train = df_train.index.max()\n",
    "    y_train = df_train['jeans']\n",
    "    exog_train = df_train[['advertising','seasonality','deviation','leftovers','cost']]\n",
    "\n",
    "    # 5) Инициализация и обучение модели SARIMAX\n",
    "    model = sm.tsa.statespace.SARIMAX(\n",
    "        y_train,\n",
    "        exog=exog_train,\n",
    "        order=(p, d, q),\n",
    "        seasonal_order=(P, D, Q, m),\n",
    "        enforce_stationarity=False,\n",
    "        enforce_invertibility=False\n",
    "    )\n",
    "    results = model.fit(disp=False)\n",
    "    print(f\"Обучена модель SARIMA({p},{d},{q})x({P},{D},{Q},{m}) AIC={results.aic:.1f}\")\n",
    "\n",
    "    # 6) Подготовка будущих экзогенных регрессоров\n",
    "    start_fc = end_train + pd.Timedelta(days=1)\n",
    "    fc_idx = pd.date_range(start=start_fc, periods=n_future, freq='D')\n",
    "    exog_fc = pd.DataFrame({\n",
    "        'advertising': advertising.reindex(fc_idx).fillna(method='ffill').fillna(0).values,\n",
    "        'seasonality': seasonality.reindex(fc_idx).fillna(method='ffill').fillna(0).values,\n",
    "        'deviation': deviation_regressor.reindex(fc_idx).fillna(method='ffill').fillna(0).values,\n",
    "        'leftovers': leftovers.reindex(fc_idx).fillna(method='ffill').fillna(0).values,\n",
    "        'cost': cost.reindex(fc_idx).fillna(method='ffill').fillna(0).values\n",
    "    }, index=fc_idx)\n",
    "\n",
    "    if need_summary:\n",
    "        return results.summary()\n",
    "\n",
    "    # 7) Прогноз\n",
    "    forecast = results.get_forecast(steps=n_future, exog=exog_fc)\n",
    "    return pd.Series(forecast.predicted_mean, index=fc_idx)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0ad08bd-142e-4025-b55d-e96c07fbf685",
   "metadata": {},
   "source": [
    "## Bayesian Structure TimeSeries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c81bc837-fd6c-484c-9cbc-b4763c3b48a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import statsmodels.api as sm\n",
    "\n",
    "def bsts_fn(\n",
    "    jeans,\n",
    "    advertising,\n",
    "    seasonality,\n",
    "    deviation_regressor,\n",
    "    leftovers,\n",
    "    cost,\n",
    "    forecast_periods=31,\n",
    "    seed=123,\n",
    "    burn=1000,\n",
    "    samples=10000\n",
    "):\n",
    "    deviation_regressor = deviation_regressor.astype(int)\n",
    "    leftovers = leftovers.astype(int)\n",
    "\n",
    "    # 1) Определяем общий период, где есть данные во всех сериях\n",
    "    series_list = [jeans, advertising, seasonality, deviation_regressor, leftovers, cost]\n",
    "    start_dates = [s.dropna().index.min() for s in series_list]\n",
    "    end_dates = [s.index.max() for s in series_list]\n",
    "    common_start = max(start_dates)\n",
    "    common_end = min(end_dates)\n",
    "\n",
    "    # 2) Создаем единый дневной индекс\n",
    "    hist_idx = pd.date_range(start=common_start, end=common_end, freq='D')\n",
    "\n",
    "    # 3) Реиндексация и заполнение\n",
    "    jeans_hist = jeans.reindex(hist_idx)\n",
    "    regressor_hist = advertising.reindex(hist_idx).fillna(method='ffill').fillna(0)\n",
    "    seasonality_hist = seasonality.reindex(hist_idx).fillna(method='ffill').fillna(0)\n",
    "    deviation_hist = deviation_regressor.reindex(hist_idx).fillna(method='ffill').fillna(0)\n",
    "    leftovers_hist = leftovers.reindex(hist_idx).fillna(method='ffill').fillna(0)\n",
    "    cost_hist = cost.reindex(hist_idx).fillna(method='ffill').fillna(0)\n",
    "    \n",
    "    df_train = pd.DataFrame({\n",
    "        'jeans': jeans_hist.values,\n",
    "        'advertising': regressor_hist.values,\n",
    "        'seasonality': seasonality_hist.values,\n",
    "        'deviation': deviation_hist.values,\n",
    "        'leftovers': leftovers_hist.values,\n",
    "        'cost': cost_hist.values\n",
    "    }, index=hist_idx).dropna(subset=['jeans'])\n",
    "\n",
    "    jeans_hist = df_train['jeans']\n",
    "    exog_hist = df_train[['advertising', 'seasonality', 'deviation', 'leftovers', 'cost']]\n",
    "\n",
    "    # Обучаем регрессионную модель\n",
    "    exog_with_const = sm.add_constant(exog_hist, has_constant='add')\n",
    "    reg_model = sm.OLS(jeans_hist, exog_with_const).fit()\n",
    "    residuals = jeans_hist - reg_model.predict(exog_with_const)\n",
    "\n",
    "    # Байесовская модель\n",
    "    bayes_uc = BayesianUnobservedComponents(\n",
    "        response=residuals,\n",
    "        level=True,\n",
    "        stochastic_level=True,\n",
    "        trend=True,\n",
    "        stochastic_trend=True,\n",
    "        trig_seasonal=((7, 0),),\n",
    "        stochastic_trig_seasonal=(True,),\n",
    "        seed=seed\n",
    "    )\n",
    "    bayes_uc.sample(samples)\n",
    "\n",
    "    # 5) Будущие значения экзогенных переменных\n",
    "    last_hist_date = df_train.index.max()\n",
    "    future_dates = pd.date_range(start=last_hist_date + pd.Timedelta(days=1), periods=forecast_periods, freq='D')\n",
    "\n",
    "    exog_future = pd.DataFrame({\n",
    "        'advertising': advertising.reindex(future_dates).fillna(method='ffill').fillna(0).values,\n",
    "        'seasonality': seasonality.reindex(future_dates).fillna(method='ffill').fillna(0).values,\n",
    "        'deviation': deviation_regressor.reindex(future_dates).fillna(method='ffill').fillna(0).values,\n",
    "        'leftovers': leftovers.reindex(future_dates).fillna(method='ffill').fillna(0).values,\n",
    "        'cost': cost.reindex(future_dates).fillna(method='ffill').fillna(0).values\n",
    "    }, index=future_dates)\n",
    "\n",
    "    exog_future_with_const = sm.add_constant(exog_future, has_constant='add')\n",
    "    exog_future_with_const = exog_future_with_const[reg_model.params.index]\n",
    "    regression_forecast = reg_model.predict(exog_future_with_const)\n",
    "\n",
    "    # Прогноз остатков\n",
    "    forecast_samples, _ = bayes_uc.forecast(num_periods=forecast_periods, burn=burn)\n",
    "    forecast_resid_mean = np.mean(forecast_samples, axis=0).squeeze()\n",
    "    forecast_resid_l95 = np.quantile(forecast_samples, 0.025, axis=0).squeeze()\n",
    "    forecast_resid_u95 = np.quantile(forecast_samples, 0.975, axis=0).squeeze()\n",
    "\n",
    "    # Финальный прогноз\n",
    "    forecast_mean = regression_forecast + forecast_resid_mean\n",
    "    forecast_l95 = regression_forecast + forecast_resid_l95\n",
    "    forecast_u95 = regression_forecast + forecast_resid_u95\n",
    "\n",
    "    forecast_series = pd.Series(forecast_mean, index=future_dates)\n",
    "    return forecast_series, forecast_l95, forecast_u95\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d80d428-c453-46a5-a061-30f1b0a2857f",
   "metadata": {},
   "source": [
    "## Генерация параметров"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "445510f0-e1c6-4419-a89d-33cced1b8e61",
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.tsa.stattools import acf, pacf, pacf_yw, pacf_ols\n",
    "from statsmodels.graphics.tsaplots import plot_acf, plot_pacf\n",
    "\n",
    "def acf_pacf_to_sarima(series, nlags=50, alpha=0.05, look_at=1, plot=False):\n",
    "    \"\"\"PACF using Yule-Walker method.\"\"\"\n",
    "    n = len(series)\n",
    "    z = abs(np.percentile(np.random.normal(size=100000), 100 * (1 - alpha / 2)))\n",
    "    conf_int = z / np.sqrt(n)\n",
    "\n",
    "\n",
    "    acf_vals = acf(series, nlags=nlags)\n",
    "    pacf_vals = pacf_yw(series, nlags=nlags, method='mle')\n",
    "\n",
    "    p = 0\n",
    "    q = 0\n",
    "\n",
    "    for val in pacf_vals[::look_at]:\n",
    "        if abs(val) > conf_int:\n",
    "            p += 1\n",
    "        else:\n",
    "            break\n",
    "\n",
    "    for val in acf_vals[::look_at]:\n",
    "        if abs(val) > conf_int:\n",
    "            q += 1\n",
    "        else:\n",
    "            break\n",
    "\n",
    "    p = min(6, p - 1)\n",
    "    q = min(6, q - 1)\n",
    "\n",
    "    if plot:\n",
    "        fig, axes = plt.subplots(2, 1, figsize=(10, 8))\n",
    "        plot_acf(series, lags=nlags, alpha=alpha, ax=axes[0])\n",
    "        axes[0].set_title(\"ACF Plot\")\n",
    "        axes[1].stem(range(len(pacf_vals)), pacf_vals)\n",
    "        axes[1].set_title(\"PACF Plot (Yule-Walker)\")\n",
    "        axes[1].axhline(conf_int, linestyle='--', color='red')\n",
    "        axes[1].axhline(-conf_int, linestyle='--', color='red')\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "    return [p, q]\n",
    "\n",
    "def is_stationary(series):\n",
    "    if series.empty:\n",
    "        return False\n",
    "    adf_p = adfuller(series.dropna())[1]\n",
    "    kpss_p = kpss(series.dropna(), regression='c')[1]\n",
    "    return adf_p < 0.05 and kpss_p > 0.05\n",
    "\n",
    "def params_generating(jeans):\n",
    "    series = jeans.copy()\n",
    "    \n",
    "    if is_stationary(jeans.diff()):\n",
    "        params = acf_pacf_to_sarima(series.diff().dropna())\n",
    "        d = 1\n",
    "    else:\n",
    "        params = acf_pacf_to_sarima(series.diff().diff().dropna())\n",
    "        d = 2\n",
    "    p, q = params[:]\n",
    "\n",
    "    if is_stationary(jeans.diff(periods=7)):\n",
    "        params = acf_pacf_to_sarima(series.diff(periods=7).dropna(), look_at=7)\n",
    "        D = 1\n",
    "    else:\n",
    "        params = acf_pacf_to_sarima(series.diff(periods=7).diff(periods=7).dropna(), look_at=7)\n",
    "        D = 2\n",
    "    P, Q = params[:]\n",
    "    return p, d, q, P, D, Q"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "785e62de-45a3-4cfb-843c-7e221be8f8a8",
   "metadata": {},
   "source": [
    "## Параметры ансамбля"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cad82ce6-c32f-4955-9055-75f06aad5619",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ensemble_params_generating(n_future, jeans, P):\n",
    "    n_iter = min(3, (len(jeans) // n_future))\n",
    "    return n_iter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2464f1e2-7397-401b-a348-13ea94febb29",
   "metadata": {},
   "source": [
    "## Определение весов ансамбля"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c110b23b-aecb-4595-a9ac-3b67198b324e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from functools import reduce\n",
    "\n",
    "def compute_model_weights(\n",
    "    y: pd.Series,\n",
    "    adv_actual: pd.Series,\n",
    "    seasonality: pd.Series,\n",
    "    deviation_regressor: pd.Series,\n",
    "    leftovers: pd.Series,\n",
    "    cost_actual: pd.Series,\n",
    "    sarima_fn,\n",
    "    prophet_fn,\n",
    "    bsts_fn,\n",
    "    n_future: int = 31,\n",
    "    p: int = 1,\n",
    "    d: int = 0,\n",
    "    q: int = 1,\n",
    "    P: int = 0,\n",
    "    D: int = 0,\n",
    "    Q: int = 0,\n",
    "    m: int = 7,\n",
    "    use_box_cox: bool = True,\n",
    "    alpha: float = 0.5,\n",
    "    offset: float = None,\n",
    "    n_splits: int = 3\n",
    ") -> dict:\n",
    "\n",
    "    def scale(series, train_idx):\n",
    "        train = series.iloc[train_idx]\n",
    "        mean, std = train.mean(), train.std()\n",
    "        std = std if std else 1  # Avoid division by zero\n",
    "        return (series - mean) / std\n",
    "\n",
    "    def safe_log1p(series, offset_val):\n",
    "        return np.log1p(series + offset_val)\n",
    "\n",
    "    def inverse_transform(preds, offset_val):\n",
    "        vals = np.expm1(preds) - offset_val if use_box_cox else preds\n",
    "        vals = np.where(np.isfinite(vals), vals, np.nan)\n",
    "        return np.nan_to_num(vals, nan=0.0, posinf=0.0, neginf=0.0)\n",
    "\n",
    "    # Prepare and align data\n",
    "    all_series = [\n",
    "        y, adv_actual, seasonality,\n",
    "        deviation_regressor, leftovers, cost_actual\n",
    "    ]\n",
    "\n",
    "    common_index = reduce(lambda a, b: a.intersection(b), [s.dropna().index for s in all_series])\n",
    "    common_index = common_index.sort_values()\n",
    "\n",
    "    # Clip everything to common index\n",
    "    y = y.loc[common_index]\n",
    "    adv_actual = adv_actual.loc[common_index]\n",
    "    seasonality = seasonality.loc[common_index]\n",
    "    deviation_regressor = deviation_regressor.loc[common_index]\n",
    "    leftovers = leftovers.loc[common_index]\n",
    "    cost_actual = cost_actual.loc[common_index]\n",
    "\n",
    "    # Sanity check\n",
    "    if len(y) < n_future * n_splits:\n",
    "        raise ValueError(\"Not enough data to perform the requested number of folds.\")\n",
    "\n",
    "    # Error accumulator\n",
    "    fold_errors = {model: [] for model in ['sarima', 'prophet', 'bsts']}\n",
    "\n",
    "    for i in range(1, n_splits + 1):\n",
    "        start = -n_future * i\n",
    "        end = -n_future * (i - 1)\n",
    "\n",
    "        y_train_raw = y.iloc[:start]\n",
    "        y_test = y.iloc[start:end] if end != 0 else y.iloc[start:]\n",
    "\n",
    "        offset_i = offset if offset is not None else (abs(y_train_raw.min()) + 1 if use_box_cox else 0)\n",
    "        y_train = safe_log1p(y_train_raw, offset_i) if use_box_cox else y_train_raw.copy()\n",
    "\n",
    "        idx = y_train.index.union(y_test.index)\n",
    "        seas = seasonality.loc[idx]\n",
    "        dev = deviation_regressor.loc[idx]\n",
    "        left = leftovers.loc[idx]\n",
    "\n",
    "        # Scale features (only unified adv and cost)\n",
    "        train_idx = y.index.get_indexer(y_train.index)\n",
    "        adv_scaled = scale(adv_actual, train_idx)\n",
    "        cost_scaled = scale(cost_actual, train_idx)\n",
    "\n",
    "        # Forecast with all models\n",
    "        preds_t = {}\n",
    "\n",
    "        # Pass the same scaled adv to both ad inputs in model functions\n",
    "        preds_t['sarima'] = sarima_fn(\n",
    "            adv_scaled,  # unified advertising in place of search/card\n",
    "            seas, y_train,\n",
    "            dev, left, cost_scaled,\n",
    "            p=p, d=d, q=q, P=P, D=D, Q=Q, m=m,\n",
    "            n_future=n_future, need_summary=False\n",
    "        ).values\n",
    "\n",
    "        # Suppress verbose output for prophet\n",
    "        silent_prophet_fn = suppress_output(prophet_fn)\n",
    "        preds_t['prophet'] = silent_prophet_fn(\n",
    "            y_train, adv_scaled,  # unified advertising twice\n",
    "            seas, dev, left, cost_scaled,\n",
    "            n_future=n_future\n",
    "        ).values\n",
    "\n",
    "        preds_t['bsts'] = bsts_fn(\n",
    "            y_train, adv_scaled,  # unified advertising twice\n",
    "            seas, dev, left, cost_scaled,\n",
    "            forecast_periods=n_future\n",
    "        )[0].values\n",
    "\n",
    "        # Inverse transform back to original scale\n",
    "        preds = {\n",
    "            model: inverse_transform(vals, offset_i)\n",
    "            for model, vals in preds_t.items()\n",
    "        }\n",
    "\n",
    "        y_true_sum = y_test.sum()\n",
    "        for model in fold_errors:\n",
    "            y_pred_sum = preds[model].sum()\n",
    "            fold_errors[model].append(\n",
    "                mean_squared_error([y_true_sum], [y_pred_sum])\n",
    "            )\n",
    "\n",
    "    # Calculate exponentially weighted average errors\n",
    "    weights_arr = np.array([alpha * (1 - alpha) ** idx for idx in range(n_splits)])\n",
    "    weights_arr /= weights_arr.sum()\n",
    "\n",
    "    exp_err = {model: np.dot(weights_arr, errs) for model, errs in fold_errors.items()}\n",
    "    inv_err = {model: 1 / err for model, err in exp_err.items()}\n",
    "    total_inv = sum(inv_err.values())\n",
    "    model_weights = {model: inv_err[model] / total_inv for model in inv_err}\n",
    "\n",
    "    return {\n",
    "        'fold_errors': fold_errors,\n",
    "        'exp_err': exp_err,\n",
    "        'model_weights': model_weights\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5e27eef-817c-4c52-b3dd-6f43bcc4249f",
   "metadata": {},
   "source": [
    "## Расчет ошибки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b11cf085-8722-483e-be67-d05ed4f3af65",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "def forecast_only(\n",
    "    y: pd.Series,\n",
    "    adv: pd.Series,\n",
    "    seasonality: pd.Series,\n",
    "    deviation_regressor: pd.Series,\n",
    "    leftovers: pd.Series,\n",
    "    cost: pd.Series,\n",
    "    sarima_fn,\n",
    "    prophet_fn,\n",
    "    bsts_fn,\n",
    "    n_future: int = 31,\n",
    "    p: int = 1,\n",
    "    d: int = 0,\n",
    "    q: int = 1,\n",
    "    P: int = 0,\n",
    "    D: int = 0,\n",
    "    Q: int = 0,\n",
    "    m: int = 7,\n",
    "    use_box_cox: bool = True,\n",
    "    offset: float = None,\n",
    "    model_weights: dict = None\n",
    ") -> dict:\n",
    "    y_train = y.copy()\n",
    "\n",
    "    offset_f = offset if offset is not None else (abs(y_train.min()) + 1 if use_box_cox else 0)\n",
    "    y_train_t = np.log1p(y_train + offset_f) if use_box_cox else y_train.copy()\n",
    "\n",
    "    def scale(series):\n",
    "        series_std = series.std()\n",
    "        if series_std == 0:\n",
    "            series_std = 1\n",
    "        return (series - series.mean()) / series_std\n",
    "\n",
    "    adv_scaled = scale(adv)\n",
    "    cost_scaled = scale(cost)\n",
    "\n",
    "    future_index = adv.index[-n_future:]  # Предполагаем, что регрессоры уже содержат нужные даты\n",
    "    seas = seasonality\n",
    "    dev = deviation_regressor\n",
    "    left = leftovers\n",
    "\n",
    "    forecasts_t = {}\n",
    "    model_times = {}\n",
    "\n",
    "    # SARIMA\n",
    "    start_time = time.time()\n",
    "    forecasts_t['sarima'] = sarima_fn(\n",
    "        adv_scaled,  # единый регрессор рекламы передаётся дважды\n",
    "        seas, y_train_t,\n",
    "        dev, left, cost_scaled,\n",
    "        p=p, d=d, q=q, P=P, D=D, Q=Q, m=int(m),\n",
    "        n_future=n_future, need_summary=False\n",
    "    ).values\n",
    "    model_times['sarima'] = time.time() - start_time\n",
    "\n",
    "    # Prophet\n",
    "    start_time = time.time()\n",
    "    silent_prophet_fn = suppress_output(prophet_fn)\n",
    "    forecasts_t['prophet'] = silent_prophet_fn(\n",
    "        y_train_t, adv_scaled,  # единый регрессор рекламы дважды\n",
    "        seas, dev, left, cost_scaled,\n",
    "        n_future=n_future\n",
    "    ).values\n",
    "    model_times['prophet'] = time.time() - start_time\n",
    "\n",
    "    # BSTS\n",
    "    start_time = time.time()\n",
    "    forecasts_t['bsts'] = bsts_fn(\n",
    "        y_train_t, adv_scaled,  # единый регрессор рекламы дважды\n",
    "        seas, dev, left, cost_scaled,\n",
    "        forecast_periods=n_future\n",
    "    )[0].values\n",
    "    model_times['bsts'] = time.time() - start_time\n",
    "\n",
    "    # Постобработка прогнозов\n",
    "    forecasts = {}\n",
    "    for m_name, vals in forecasts_t.items():\n",
    "        if use_box_cox:\n",
    "            pred_vals = np.expm1(vals) - offset_f\n",
    "        else:\n",
    "            pred_vals = vals\n",
    "        pred_vals = np.where(np.isfinite(pred_vals), pred_vals, np.nan)\n",
    "        pred_vals = np.nan_to_num(pred_vals, nan=0.0, posinf=0.0, neginf=0.0)\n",
    "        forecasts[m_name] = pred_vals\n",
    "\n",
    "    if model_weights is None:\n",
    "        raise ValueError(\"model_weights must be provided for ensemble forecast\")\n",
    "\n",
    "    ensemble = sum(model_weights[m_name] * forecasts[m_name] for m_name in model_weights)\n",
    "    ensemble = np.where(np.isfinite(ensemble), ensemble, np.nan)\n",
    "    ensemble = np.nan_to_num(ensemble, nan=0.0, posinf=0.0, neginf=0.0)\n",
    "\n",
    "    return {\n",
    "        'forecast_dates': future_index,\n",
    "        'model_forecasts': forecasts,\n",
    "        'ensemble_forecast': ensemble,\n",
    "        'model_times': model_times\n",
    "    }\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:myenv]",
   "language": "python",
   "name": "conda-env-myenv-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
